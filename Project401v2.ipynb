{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "57865fcb89c5e01d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-07T22:06:57.126672Z",
     "start_time": "2025-12-07T22:06:55.876827Z"
    }
   },
   "source": [
    "import nltk\n",
    "import re\n",
    "import os\n",
    "from nltk.corpus.reader import CHILDESCorpusReader\n",
    "from nltk import FreqDist, word_tokenize, bigrams, ConditionalFreqDist\n",
    "import pylangacq\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# I had to install pylangacq like this for it to work in jupiter\n",
    "#import sys\n",
    "#!\"$sys.executable\" -m pip install pylangacq"
   ],
   "id": "a070eac5a7bdd21a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "pylangnacq source\n",
    "\n",
    "@TechReport{lee-et-al-pylangacq:2016,\n",
    "   Title       = {Working with CHAT transcripts in Python},\n",
    "   Author      = {Lee, Jackson L. and Burkholder, Ross and Flinn, Gallagher B. and Coppess, Emily R.},\n",
    "   Institution = {Department of Computer Science, University of Chicago},\n",
    "   Year        = {2016},\n",
    "   Number      = {TR-2016-02},\n",
    "}"
   ],
   "id": "1b4378bc47913c95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T23:22:12.211408Z",
     "start_time": "2025-12-08T23:21:45.229876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # # Set Up\n",
    "\n",
    "# Put the Hoff folder in the project root, copy the path into the reader.\n",
    "# Create the hoff reader\n",
    "hre = pylangacq.read_chat('/Users/baeddanhemphill/Desktop/Ling_401/Homeworks/Hoff')\n",
    "hre.n_files()\n",
    "\n",
    "# Separate by eng,span,mono\n",
    "# The metadata for age 2.5 is missing dependent tier data, so focus only on ages 3/3.5\n",
    "#.filter(keep, remove)\n",
    "eng_files = hre.filter('biling-eng', '2.5')\n",
    "span_files = hre.filter('biling-spa', '2.5')\n",
    "mono_files = hre.filter('mono', '2.5')\n"
   ],
   "id": "e451d34d982a5e07",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T23:21:35.417108Z",
     "start_time": "2025-12-08T23:21:33.805680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check specific tier contents\n",
    "pos_set = set()\n",
    "for utt in hre.utterances():\n",
    "    for tok in utt.tokens:\n",
    "        if tok.pos:\n",
    "            pos_set.add(tok.pos)\n",
    "#pos_set\n",
    "\n",
    "mor_set = set()\n",
    "for utt in hre.utterances():\n",
    "    for tok in utt.tokens:\n",
    "        if tok.mor:\n",
    "            mor_set.add(tok.mor.split(\"|\")[0])  # category part\n",
    "#mor_set"
   ],
   "id": "debfac506365439e",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def corpus_to_chi_df_v1(corpus):\n",
    "    cols = []\n",
    "    for file_path in corpus.file_paths():\n",
    "\n",
    "        # Get ages for CHI in this file\n",
    "        single_file_reader = corpus.filter(file_path)\n",
    "        chi_ages = single_file_reader.ages('CHI')\n",
    "        age = chi_ages[0] if chi_ages else None\n",
    "\n",
    "        # Iterate over CHI utterances\n",
    "        for utt in single_file_reader.utterances(participants='CHI'):\n",
    "\n",
    "            #Only include the utterences containing a verb\n",
    "            if not any(tok.pos == \"verb\" or tok.pos == \"aux\" for tok in utt.tokens):\n",
    "                continue\n",
    "\n",
    "            tokens = [tok.word for tok in utt.tokens]\n",
    "            text = \" \".join(tokens).strip()\n",
    "            cols.append({\n",
    "                \"age\": age,\n",
    "                \"utterance\": text,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(cols)"
   ],
   "id": "a80cbc224f819404"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T22:53:19.827838Z",
     "start_time": "2025-12-08T22:53:19.794224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def corpus_to_chi_df_v2(corpus):\n",
    "    cols = []\n",
    "    for file_path in corpus.file_paths():\n",
    "\n",
    "        # Get ages for CHI in this file\n",
    "        single_file_reader = corpus.filter(file_path)\n",
    "        chi_ages = single_file_reader.ages('CHI')\n",
    "        age = chi_ages[0] if chi_ages else None\n",
    "\n",
    "        # Determine language filter based on file path\n",
    "        # This will filter out code switching in target language.\n",
    "        if \"biling-eng\" in file_path:\n",
    "            exclude_marker = \"[- spa]\"\n",
    "        elif \"biling-spa\" in file_path:\n",
    "            exclude_marker = \"[- eng]\"\n",
    "        else:\n",
    "            exclude_marker = \"[-RANDOM PHRASE NOT IN TEXTS SUCH AS THIS ONE]\"\n",
    "\n",
    "        # Iterate over CHI utterances\n",
    "        for utt in single_file_reader.utterances(participants='CHI'):\n",
    "\n",
    "            tokens = utt.tokens\n",
    "            pos = [token.pos for token in tokens ]\n",
    "\n",
    "            # Remove 'no' only for Spanish files\n",
    "            if \"biling-spa\" in file_path:\n",
    "                keep_indices = [i for i, w in enumerate(tokens) if w.word.lower() != \"no\"]\n",
    "                tokens = [tokens[i] for i in keep_indices]\n",
    "                pos = [pos[i] for i in keep_indices]\n",
    "\n",
    "            # Only include utterances containing a verb\n",
    "            if not any(p in (\"verb\", \"aux\") for p in pos):\n",
    "                continue\n",
    "\n",
    "            # Only include utterances in target language\n",
    "            badtext = utt.tiers['CHI']\n",
    "            if exclude_marker in badtext:\n",
    "                continue\n",
    "\n",
    "            words = [tok.word for tok in tokens]\n",
    "            text = \" \".join(words).strip()\n",
    "\n",
    "            # Determine pronoun-before-verb\n",
    "            pronoun_before_verb = False\n",
    "            pron_verb_bigram = None\n",
    "\n",
    "            for i, p in enumerate(pos):\n",
    "\n",
    "                if p == \"pron\" and i+1 < len(pos) and pos[i+1] in (\"verb\", \"aux\"):\n",
    "                    pronoun_before_verb = True\n",
    "                    pron_verb_bigram = (words[i], words[i+1])\n",
    "                    break\n",
    "\n",
    "                if p in (\"verb\", \"aux\"):\n",
    "                    break\n",
    "\n",
    "                if p == \"pron\":\n",
    "                    pronoun_before_verb = True\n",
    "\n",
    "            verb_morphs = [tok.mor for tok in tokens\n",
    "                           if tok.pos in (\"verb\", \"aux\") and tok.mor]\n",
    "\n",
    "            cols.append({\n",
    "                \"age\": age,\n",
    "                \"utterance\": text,\n",
    "                \"pronoun_before_verb\": pronoun_before_verb,\n",
    "                \"pron_verb_bigram\": pron_verb_bigram,\n",
    "                \"morphs\": verb_morphs\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(cols)"
   ],
   "id": "ad8ebd91cda397b2",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T23:11:10.131540Z",
     "start_time": "2025-12-08T23:11:10.127376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def spanish_pronoun_requirement_filter(df):\n",
    "    required = {\"S3\", \"P3\", \"P2\"}\n",
    "    optional = {\"S1\", \"S2\", \"P1\"}\n",
    "    new_cols = []\n",
    "\n",
    "    for morph_list in df[\"morphs\"]:\n",
    "        person_num = None\n",
    "\n",
    "        for morph in morph_list:\n",
    "            if \"-Fin-\" in morph or \"-Aux-\" in morph:\n",
    "                parts = morph.split(\"-\")\n",
    "                if len(parts) >= 4:\n",
    "                    person_num = parts[-1]  # last part is person-number\n",
    "                break\n",
    "\n",
    "        if person_num is None:\n",
    "            new_cols.append(\"unknown\")\n",
    "        elif person_num in required:\n",
    "            new_cols.append(\"required\")\n",
    "        elif person_num in optional:\n",
    "            new_cols.append(\"optional\")\n",
    "        else:\n",
    "            new_cols.append(\"unknown\")\n",
    "\n",
    "    df[\"pronoun_requirement\"] = new_cols\n",
    "    return df"
   ],
   "id": "623f6106fcb6b31f",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T23:20:50.547024Z",
     "start_time": "2025-12-08T23:20:50.454214Z"
    }
   },
   "cell_type": "code",
   "source": "span_df_v2 = spanish_pronoun_requirement_filter(corpus_to_chi_df_v2(span_files))",
   "id": "305ab2974b748837",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T23:20:52.230612Z",
     "start_time": "2025-12-08T23:20:52.225656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def spanish_pronoun_usage_stats(df):\n",
    "\n",
    "    required_df = df[df[\"pronoun_requirement\"] == \"required\"]\n",
    "\n",
    "    # Count True/False for pronoun_before_verb\n",
    "    counts = required_df[\"pronoun_before_verb\"].value_counts(sort=False)\n",
    "    total = counts.sum()\n",
    "\n",
    "    # Compute percentages\n",
    "    percentages = (counts / total * 100).round(1)\n",
    "\n",
    "    # Ensure True appears first\n",
    "    stats_df = pd.DataFrame({\n",
    "        \"count\": counts,\n",
    "        \"percent\": percentages.map(\"{:.1f}%\".format)\n",
    "    }).reindex([True, False])\n",
    "\n",
    "    print(\"Pronoun use when required:\")\n",
    "    print(stats_df)"
   ],
   "id": "1f86fdf7280b4b42",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T23:22:49.609109Z",
     "start_time": "2025-12-08T23:22:49.122667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### PRINT THE RESULTS!\n",
    "\n",
    "hoffdataframes = [\n",
    "corpus_to_chi_df_v2(mono_files),\n",
    "corpus_to_chi_df_v2(eng_files),\n",
    "corpus_to_chi_df_v2(span_files)\n",
    "]\n",
    "\n",
    "groupnames = [\n",
    "\"Mono-English\",\n",
    "\"Biling-English\",\n",
    "\"Biling-Spanish\"\n",
    "]\n",
    "\n",
    "for name, df in zip(groupnames, hoffdataframes):\n",
    "    counts = df['pronoun_before_verb'].value_counts()\n",
    "    percent = df['pronoun_before_verb'].value_counts(normalize=True) * 100\n",
    "\n",
    "    display_df = pd.DataFrame({\n",
    "        \"Count\": counts,\n",
    "        \"Percent\": percent.map(\"{:.1f}%\".format)\n",
    "    }).reindex([True, False])\n",
    "\n",
    "    print(f\"--- {name} Group ---\")\n",
    "    print(display_df)\n",
    "    print(\"\\n\")\n",
    "spanish_pronoun_usage_stats(span_df_v2)"
   ],
   "id": "57e2dc923eec55cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Mono-English Group ---\n",
      "                     Count Percent\n",
      "pronoun_before_verb               \n",
      "True                  3835   70.1%\n",
      "False                 1639   29.9%\n",
      "\n",
      "\n",
      "--- Biling-English Group ---\n",
      "                     Count Percent\n",
      "pronoun_before_verb               \n",
      "True                  4050   65.1%\n",
      "False                 2170   34.9%\n",
      "\n",
      "\n",
      "--- Biling-Spanish Group ---\n",
      "                     Count Percent\n",
      "pronoun_before_verb               \n",
      "True                  2544   43.3%\n",
      "False                 3333   56.7%\n",
      "\n",
      "\n",
      "Pronoun use when required:\n",
      "                     count percent\n",
      "pronoun_before_verb               \n",
      "True                  1666   45.8%\n",
      "False                 1968   54.2%\n"
     ]
    }
   ],
   "execution_count": 109
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
