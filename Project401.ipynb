{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "57865fcb89c5e01d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-07T22:06:57.126672Z",
     "start_time": "2025-12-07T22:06:55.876827Z"
    }
   },
   "source": [
    "import nltk\n",
    "import re\n",
    "import os\n",
    "from nltk.corpus.reader import CHILDESCorpusReader\n",
    "from nltk import FreqDist, word_tokenize, bigrams, ConditionalFreqDist\n",
    "import pylangacq\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# I had to install pylangacq like this for it to work in jupiter\n",
    "#import sys\n",
    "#!\"$sys.executable\" -m pip install pylangacq"
   ],
   "id": "a070eac5a7bdd21a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "pylangnacq source\n",
    "\n",
    "@TechReport{lee-et-al-pylangacq:2016,\n",
    "   Title       = {Working with CHAT transcripts in Python},\n",
    "   Author      = {Lee, Jackson L. and Burkholder, Ross and Flinn, Gallagher B. and Coppess, Emily R.},\n",
    "   Institution = {Department of Computer Science, University of Chicago},\n",
    "   Year        = {2016},\n",
    "   Number      = {TR-2016-02},\n",
    "}"
   ],
   "id": "1b4378bc47913c95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T22:07:08.931608Z",
     "start_time": "2025-12-07T22:06:59.612574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # # Set Up\n",
    "\n",
    "# Put the Hoff folder in the project root, copy the path into the reader.\n",
    "# Create the hoff reader\n",
    "hre = pylangacq.read_chat('/Users/baeddanhemphill/Desktop/Ling_401/Homeworks/Hoff')\n",
    "hre.n_files()\n",
    "\n",
    "# Separate by eng,span,mono\n",
    "# The metadata for age 2.5 is missing dependent tier data, so focus only on ages 3/3.5\n",
    "#.filter(keep, remove)\n",
    "eng_files = hre.filter('biling-eng', '2.5')\n",
    "span_files = hre.filter('biling-spa', '2.5')\n",
    "mono_files = hre.filter('mono', '2.5')\n",
    "\n",
    "\n",
    "# Define pronouns\n",
    "eng_pnns_sg = {'i', 'you', 'he', 'she', 'it'}\n",
    "eng_pnns_pl = {'we', 'they'}\n",
    "span_pnns_sg = {'yo', 'tu', 'él', 'ella', 'usted'}\n",
    "span_pnns_pl = {'nosotros', 'nosotras', 'ellos', 'ellas', 'ustedes'}"
   ],
   "id": "e451d34d982a5e07",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "hre.headers()",
   "id": "1c5321f6460bccf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def pos_list(files):\n",
    "     poss = [token.pos for token in files.tokens(participants = 'CHI')]\n",
    "     return poss"
   ],
   "id": "725c3b1ca3d25a8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def corpus_to_chi_df_v1(corpus):\n",
    "    cols = []\n",
    "    for file_path in corpus.file_paths():\n",
    "\n",
    "        # Get ages for CHI in this file\n",
    "        single_file_reader = corpus.filter(file_path)\n",
    "        chi_ages = single_file_reader.ages('CHI')\n",
    "        age = chi_ages[0] if chi_ages else None\n",
    "\n",
    "        # Iterate over CHI utterances\n",
    "        for utt in single_file_reader.utterances(participants='CHI'):\n",
    "\n",
    "            #Only include the utterences containing a verb\n",
    "            if not any(tok.pos == \"verb\" or tok.pos == \"aux\" for tok in utt.tokens):\n",
    "                continue\n",
    "\n",
    "            tokens = [tok.word for tok in utt.tokens]\n",
    "            text = \" \".join(tokens).strip()\n",
    "            cols.append({\n",
    "                \"age\": age,\n",
    "                \"utterance\": text,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(cols)\n",
    "\n",
    "corpus_to_chi_df_v1(eng_files)"
   ],
   "id": "4bf6d18783cdfba5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "eng_df = corpus_to_chi_df(eng_files)\n",
    "span_df = corpus_to_chi_df(span_files)\n",
    "mono_df = corpus_to_chi_df(mono_files)\n",
    "\n",
    "#The dependent fields in 2.5 are broken :(\n",
    "valid_ages = ['3;0', '3;6']\n",
    "eng_df = eng_df[eng_df['age'].isin(valid_ages)]\n",
    "span_df = span_df[span_df['age'].isin(valid_ages)]\n",
    "mono_df = mono_df[mono_df['age'].isin(valid_ages)]\n",
    "\n"
   ],
   "id": "8192db230dae8494"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pos_set = set()\n",
    "for utt in hre.utterances():\n",
    "    for tok in utt.tokens:\n",
    "        if tok.pos:\n",
    "            pos_set.add(tok.pos)\n",
    "pos_set"
   ],
   "id": "debfac506365439e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mor_set = set()\n",
    "for utt in hre.utterances():\n",
    "    for tok in utt.tokens:\n",
    "        if tok.mor:\n",
    "            mor_set.add(tok.mor.split(\"|\")[0])  # category part\n",
    "mor_set"
   ],
   "id": "a371cb0124a94d69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T16:23:14.358486Z",
     "start_time": "2025-12-08T16:23:14.176767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def corpus_to_chi_df_v2(corpus):\n",
    "    cols = []\n",
    "    for file_path in corpus.file_paths():\n",
    "\n",
    "        # Get ages for CHI in this file\n",
    "        single_file_reader = corpus.filter(file_path)\n",
    "        chi_ages = single_file_reader.ages('CHI')\n",
    "        age = chi_ages[0] if chi_ages else None\n",
    "\n",
    "        # Iterate over CHI utterances\n",
    "        for utt in single_file_reader.utterances(participants='CHI'):\n",
    "\n",
    "            tokens = utt.tokens\n",
    "            pos = [token.pos for token in tokens ]  # access POS list\n",
    "\n",
    "            # Only include utterances containing a verb\n",
    "            if not any(p in (\"verb\", \"aux\") for p in pos):\n",
    "                continue\n",
    "\n",
    "            words = [tok.word for tok in utt.tokens]  # convert to list of words\n",
    "            text = \" \".join(words).strip()\n",
    "\n",
    "            # Determine pronoun-before-verb\n",
    "            pronoun_before_verb = False\n",
    "            pron_verb_bigram = None\n",
    "\n",
    "            for i, p in enumerate(pos):\n",
    "                # pronoun–verb bigram\n",
    "                if p == \"pron\" and i+1 < len(pos) and pos[i+1] in (\"verb\", \"aux\"):\n",
    "                    pronoun_before_verb = True\n",
    "                    pron_verb_bigram = (words[i], words[i+1])\n",
    "                    break\n",
    "\n",
    "                # any pronoun before first verb\n",
    "                if p in (\"verb\", \"aux\"):\n",
    "                    break\n",
    "                if p == \"pron\":\n",
    "                    pronoun_before_verb = True\n",
    "\n",
    "            cols.append({\n",
    "                \"age\": age,\n",
    "                \"utterance\": text,\n",
    "                \"pronoun_before_verb\": pronoun_before_verb,\n",
    "                \"pron_verb_bigram\": pron_verb_bigram\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(cols)\n",
    "\n",
    "corpus_to_chi_df_v2(eng_files)"
   ],
   "id": "ad8ebd91cda397b2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            age                 utterance  pronoun_before_verb  \\\n",
       "0     (2, 6, 0)         a ver los patos .                False   \n",
       "1     (2, 6, 0)                   llama .                False   \n",
       "2     (2, 6, 0)                 pon eso .                False   \n",
       "3     (2, 6, 0)                 take it .                False   \n",
       "4     (2, 6, 0)                  put it ?                False   \n",
       "...         ...                       ...                  ...   \n",
       "7093  (3, 0, 0)   esto se está acabando .                 True   \n",
       "7094  (3, 0, 0)         podemos también ?                False   \n",
       "7095  (3, 0, 0)                 I like /.                 True   \n",
       "7096  (3, 0, 0)  esto no se puede bajar .                 True   \n",
       "7097  (3, 0, 0)      eso está muy sucio .                 True   \n",
       "\n",
       "     pron_verb_bigram  \n",
       "0                None  \n",
       "1                None  \n",
       "2                None  \n",
       "3                None  \n",
       "4                None  \n",
       "...               ...  \n",
       "7093       (se, está)  \n",
       "7094             None  \n",
       "7095        (I, like)  \n",
       "7096      (se, puede)  \n",
       "7097      (eso, está)  \n",
       "\n",
       "[7098 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>utterance</th>\n",
       "      <th>pronoun_before_verb</th>\n",
       "      <th>pron_verb_bigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(2, 6, 0)</td>\n",
       "      <td>a ver los patos .</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2, 6, 0)</td>\n",
       "      <td>llama .</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2, 6, 0)</td>\n",
       "      <td>pon eso .</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(2, 6, 0)</td>\n",
       "      <td>take it .</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(2, 6, 0)</td>\n",
       "      <td>put it ?</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7093</th>\n",
       "      <td>(3, 0, 0)</td>\n",
       "      <td>esto se está acabando .</td>\n",
       "      <td>True</td>\n",
       "      <td>(se, está)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7094</th>\n",
       "      <td>(3, 0, 0)</td>\n",
       "      <td>podemos también ?</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7095</th>\n",
       "      <td>(3, 0, 0)</td>\n",
       "      <td>I like /.</td>\n",
       "      <td>True</td>\n",
       "      <td>(I, like)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>(3, 0, 0)</td>\n",
       "      <td>esto no se puede bajar .</td>\n",
       "      <td>True</td>\n",
       "      <td>(se, puede)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>(3, 0, 0)</td>\n",
       "      <td>eso está muy sucio .</td>\n",
       "      <td>True</td>\n",
       "      <td>(eso, está)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7098 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
