{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "57865fcb89c5e01d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-07T22:06:57.126672Z",
     "start_time": "2025-12-07T22:06:55.876827Z"
    }
   },
   "source": [
    "import nltk\n",
    "import re\n",
    "import os\n",
    "from nltk.corpus.reader import CHILDESCorpusReader\n",
    "from nltk import FreqDist, word_tokenize, bigrams, ConditionalFreqDist\n",
    "import pylangacq\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# I had to install pylangacq like this for it to work in jupiter\n",
    "#import sys\n",
    "#!\"$sys.executable\" -m pip install pylangacq"
   ],
   "id": "a070eac5a7bdd21a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "pylangnacq source\n",
    "\n",
    "@TechReport{lee-et-al-pylangacq:2016,\n",
    "   Title       = {Working with CHAT transcripts in Python},\n",
    "   Author      = {Lee, Jackson L. and Burkholder, Ross and Flinn, Gallagher B. and Coppess, Emily R.},\n",
    "   Institution = {Department of Computer Science, University of Chicago},\n",
    "   Year        = {2016},\n",
    "   Number      = {TR-2016-02},\n",
    "}"
   ],
   "id": "1b4378bc47913c95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T22:07:08.931608Z",
     "start_time": "2025-12-07T22:06:59.612574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # # Set Up\n",
    "\n",
    "# Put the Hoff folder in the project root, copy the path into the reader.\n",
    "# Create the hoff reader\n",
    "hre = pylangacq.read_chat('/Users/baeddanhemphill/Desktop/Ling_401/Homeworks/Hoff')\n",
    "hre.n_files()\n",
    "\n",
    "# Separate by eng,span,mono\n",
    "# The metadata for age 2.5 is missing dependent tier data, so focus only on ages 3/3.5\n",
    "#.filter(keep, remove)\n",
    "eng_files = hre.filter('biling-eng', '2.5')\n",
    "span_files = hre.filter('biling-spa', '2.5')\n",
    "mono_files = hre.filter('mono', '2.5')\n",
    "\n",
    "\n",
    "# Define pronouns\n",
    "eng_pnns_sg = {'i', 'you', 'he', 'she', 'it'}\n",
    "eng_pnns_pl = {'we', 'they'}\n",
    "span_pnns_sg = {'yo', 'tu', 'Ã©l', 'ella', 'usted'}\n",
    "span_pnns_pl = {'nosotros', 'nosotras', 'ellos', 'ellas', 'ustedes'}"
   ],
   "id": "e451d34d982a5e07",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check specific tier contents\n",
    "pos_set = set()\n",
    "for utt in hre.utterances():\n",
    "    for tok in utt.tokens:\n",
    "        if tok.pos:\n",
    "            pos_set.add(tok.pos)\n",
    "pos_set\n",
    "\n",
    "mor_set = set()\n",
    "for utt in hre.utterances():\n",
    "    for tok in utt.tokens:\n",
    "        if tok.mor:\n",
    "            mor_set.add(tok.mor.split(\"|\")[0])  # category part\n",
    "mor_set"
   ],
   "id": "debfac506365439e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def corpus_to_chi_df_v1(corpus):\n",
    "    cols = []\n",
    "    for file_path in corpus.file_paths():\n",
    "\n",
    "        # Get ages for CHI in this file\n",
    "        single_file_reader = corpus.filter(file_path)\n",
    "        chi_ages = single_file_reader.ages('CHI')\n",
    "        age = chi_ages[0] if chi_ages else None\n",
    "\n",
    "        # Iterate over CHI utterances\n",
    "        for utt in single_file_reader.utterances(participants='CHI'):\n",
    "\n",
    "            #Only include the utterences containing a verb\n",
    "            if not any(tok.pos == \"verb\" or tok.pos == \"aux\" for tok in utt.tokens):\n",
    "                continue\n",
    "\n",
    "            tokens = [tok.word for tok in utt.tokens]\n",
    "            text = \" \".join(tokens).strip()\n",
    "            cols.append({\n",
    "                \"age\": age,\n",
    "                \"utterance\": text,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(cols)"
   ],
   "id": "a80cbc224f819404"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def corpus_to_chi_df_v2(corpus):\n",
    "    cols = []\n",
    "    for file_path in corpus.file_paths():\n",
    "\n",
    "        # Get ages for CHI in this file\n",
    "        single_file_reader = corpus.filter(file_path)\n",
    "        chi_ages = single_file_reader.ages('CHI')\n",
    "        age = chi_ages[0] if chi_ages else None\n",
    "\n",
    "        # Determine language filter based on file path\n",
    "        # This will filter out code switching in target language.\n",
    "        if \"biling-eng\" in file_path:\n",
    "            exclude_marker = \"[- spa]\"\n",
    "        elif \"biling-spa\" in file_path:\n",
    "            exclude_marker = \"[- eng]\"\n",
    "        else:\n",
    "            exclude_marker = \"[-RANDOM PHRASE NOT IN TEXTS SUCH AS THIS ONE]\"\n",
    "\n",
    "        # Iterate over CHI utterances\n",
    "        for utt in single_file_reader.utterances(participants='CHI'):\n",
    "\n",
    "            tokens = utt.tokens\n",
    "            pos = [token.pos for token in tokens ]  # access POS list\n",
    "\n",
    "            # Only include utterances containing a verb\n",
    "            if not any(p in (\"verb\", \"aux\") for p in pos):\n",
    "                continue\n",
    "\n",
    "            # Only include utterances in target language\n",
    "            badtext = utt.tiers['CHI']\n",
    "            if exclude_marker in badtext:\n",
    "                continue\n",
    "\n",
    "            words = [tok.word for tok in utt.tokens]\n",
    "            text = \" \".join(words).strip()\n",
    "\n",
    "            # Determine pronoun-before-verb\n",
    "            pronoun_before_verb = False\n",
    "            pron_verb_bigram = None\n",
    "\n",
    "            for i, p in enumerate(pos):\n",
    "\n",
    "                if p == \"pron\" and i+1 < len(pos) and pos[i+1] in (\"verb\", \"aux\"):\n",
    "                    pronoun_before_verb = True\n",
    "                    pron_verb_bigram = (words[i], words[i+1])\n",
    "                    break\n",
    "\n",
    "                if p in (\"verb\", \"aux\"):\n",
    "                    break\n",
    "\n",
    "                if p == \"pron\":\n",
    "                    pronoun_before_verb = True\n",
    "\n",
    "            cols.append({\n",
    "                \"age\": age,\n",
    "                \"utterance\": text,\n",
    "                \"pronoun_before_verb\": pronoun_before_verb,\n",
    "                \"pron_verb_bigram\": pron_verb_bigram\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(cols)\n"
   ],
   "id": "ad8ebd91cda397b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T19:49:41.540907Z",
     "start_time": "2025-12-08T19:49:37.245002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### PRINT THE RESULTS!\n",
    "\n",
    "hoffdataframes = [corpus_to_chi_df_v2(eng_files),\n",
    "corpus_to_chi_df_v2(span_files),\n",
    "corpus_to_chi_df_v2(mono_files)]\n",
    "\n",
    "group_names = [\"Biling-English\", \"Biling-Spanish\", \"Mono-English\"]\n",
    "\n",
    "for name, df in zip(group_names, hoffdataframes):\n",
    "    counts = df['pronoun_before_verb'].value_counts()\n",
    "    percent = df['pronoun_before_verb'].value_counts(normalize=True) * 100\n",
    "\n",
    "    display_df = pd.DataFrame({\n",
    "        \"Count\": counts,\n",
    "        \"Percent\": percent.map(\"{:.1f}%\".format)\n",
    "    }).reindex([True, False])\n",
    "\n",
    "    print(f\"--- {name} Group ---\")\n",
    "    print(display_df)\n",
    "    print(\"\\n\")"
   ],
   "id": "f26ebc1324d9d6f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Biling-English Group ---\n",
      "                     Count Percent\n",
      "pronoun_before_verb               \n",
      "True                  4050   65.1%\n",
      "False                 2170   34.9%\n",
      "\n",
      "\n",
      "--- Biling-Spanish Group ---\n",
      "                     Count Percent\n",
      "pronoun_before_verb               \n",
      "True                  2544   43.3%\n",
      "False                 3333   56.7%\n",
      "\n",
      "\n",
      "--- Mono Group ---\n",
      "                     Count Percent\n",
      "pronoun_before_verb               \n",
      "True                  3835   70.1%\n",
      "False                 1639   29.9%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 57
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
